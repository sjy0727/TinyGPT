import os
import random

import numpy as np
import pandas as pd
import streamlit as st
import cv2

st.set_page_config(
    page_title="Video Annotation Tool",
    page_icon='ğŸ“Œ',
    layout="wide"
)

######################### é¡µé¢å®šä¹‰åŒºï¼ˆä¾§è¾¹æ ï¼‰ ########################
st.sidebar.title('ğŸ“Œ Video Facial Emotion æ ‡æ³¨å¹³å°')
st.sidebar.markdown('''
    ```python
    ç”¨äºè§†é¢‘ä¸­é¢éƒ¨æƒ…ç»ªçš„æ ‡æ³¨ã€‚
    ```
''')
st.sidebar.markdown('æ ‡æ³¨æ€è·¯å‚è€ƒè‡ª [InstructGPT](https://arxiv.org/pdf/2203.02155.pdf) ã€‚')
st.sidebar.markdown('RLHF æ›´å¤šä»‹ç»ï¼š[æƒ³è®­ç»ƒChatGPTï¼Ÿå¾—...](https://zhuanlan.zhihu.com/p/595579042)')
st.sidebar.header('âš™ï¸ Model Config')
st.sidebar.write('å½“å‰æ ‡æ³¨é…ç½®ï¼ˆå¯åœ¨æºç ä¸­ä¿®æ”¹ï¼‰ï¼š')

# label_tab, dataset_tab = st.tabs(['Label', 'Dataset'])

# with label_tab:
#     with st.expander('ğŸ” Setting Prompts', expanded=True):
#         random_button = st.button('éšæœº prompt', help='ä»promptæ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªpromptï¼Œå¯é€šè¿‡ä¿®æ”¹æºç ä¸­ MODEL_CONFIG["random_prompts"] å‚æ•°æ¥è‡ªå®šä¹‰promptæ± ã€‚')
#         if random_button:
#             prompt_text = random.choice(MODEL_CONFIG['random_prompts'])
#         else:
#             prompt_text = st.session_state['current_prompt']


# åŠ è½½è§†é¢‘
uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=["mp4"])

if uploaded_file is not None:
    video = cv2.VideoCapture(os.path.join('/Users/sunjunyi/Downloads',uploaded_file.name))
    frame_rate = int(video.get(cv2.CAP_PROP_FPS))

    frame_number = st.number_input("å¸§ç¼–å·", value=0, min_value=0, max_value=int(video.get(cv2.CAP_PROP_FRAME_COUNT)))
    video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)

    ret, frame = video.read()
    if ret:
        st.image(frame, channels="BGR", use_column_width=True)

    emotion_options = ["å–œæ‚¦", "æ„¤æ€’", "æ‚²ä¼¤", "å®³æ€•", "æƒŠè®¶", "ä¸­æ€§"]
    selected_emotion = st.selectbox("é€‰æ‹©æƒ…ç»ª", emotion_options)

    arousal_rating = st.slider("å”¤é†’è¯„åˆ†", min_value=1, max_value=10, value=5)

    st.write(f"å½“å‰å¸§æ ‡ç­¾: æƒ…ç»ª - {selected_emotion}, å”¤é†’è¯„åˆ† - {arousal_rating}")

    st.write(f"å½“å‰æ ‡è®°è¿›åº¦: {frame_number}/{int(video.get(cv2.CAP_PROP_FRAME_COUNT))}")
else:
    st.write("è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
